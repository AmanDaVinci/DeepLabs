{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Vision\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author** : Aman Hussain  \n",
    "**Email** : aman@amandavinci.me  \n",
    "**Description** : Classifying images of dogs and cats by finetuning the VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scientific Computing Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "from helper import utils\n",
    "from helper.utils import plots\n",
    "\n",
    "from helper import vgg16\n",
    "from helper.vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring paths & global parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the dataset is defined here. It will point to the sample folder which contains lesser number of images for quick and iterative training on the local machine. For the final training, on the cloud we must change the path to the one commented out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = '../data/dogscats/sample/'\n",
    "path = '../data/dogscats/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default batchsize for training and validation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the VGG16 class which implements the required utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.fast.ai/models/vgg16.h5\n",
      "553484288/553482496 [==============================] - 53s    \n",
      "Downloading data from http://files.fast.ai/models/imagenet_class_index.json\n",
      "32768/35363 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the training and validation batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=batchsize)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the images, only if we are exploring the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path == '../data/dogscats/sample/':\n",
    "    imgs, labels = next(batches)\n",
    "    val_imgs, val_labels = next(val_batches)\n",
    "    labels = ['dog' if i[0]==0 else 'cat' for i in labels]\n",
    "    val_labels = ['dog' if i[0]==0 else 'cat' for i in val_labels]\n",
    "    plots(val_imgs, figsize=(20,10), titles=val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 636s - loss: 0.1244 - acc: 0.9671 - val_loss: 0.0660 - val_acc: 0.9820\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 633s - loss: 0.0960 - acc: 0.9774 - val_loss: 0.0590 - val_acc: 0.9852\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 634s - loss: 0.0884 - acc: 0.9783 - val_loss: 0.0638 - val_acc: 0.9856\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 634s - loss: 0.0993 - acc: 0.9780 - val_loss: 0.0654 - val_acc: 0.9842\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 633s - loss: 0.0880 - acc: 0.9806 - val_loss: 0.0716 - val_acc: 0.9832\n",
      "CPU times: user 1h 3min 27s, sys: 12min 31s, total: 1h 15min 59s\n",
      "Wall time: 54min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vgg.fit(batches, val_batches, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the quirkiness of the ImageDataGenerator.flow_from_directory() used by vgg.get_batches(), we have to make a sub directory under test directory by the name 'subdir_for_keras_ImageDataGenerator'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = len(os.listdir(path+'test'+'/subdir_for_keras_ImageDataGenerator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the class_mode set to None, it will return only the batch of images without labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "testbatch = vgg.get_batches(path+'test', shuffle=False, batch_size=batch_size, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs = next(testbatch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,we visualize the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path == '../data/dogscats/sample/':\n",
    "    plots(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make the predictions using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 1min 15s, total: 5min 25s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "probab, prediction, prediction_labels = vgg.predict(test_imgs, details = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing to save the predictions as submissions to the Kaggle competetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(path+'submissions/probab', probab)\n",
    "np.save(path+'submissions/prediction', prediction)\n",
    "np.save(path+'submissions/prediction_labels', prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = [str(i) for i in range(1, batch_size+1)]\n",
    "index.insert(0, 'id')\n",
    "\n",
    "labels_pred = [str(label) for label in prediction]\n",
    "labels_pred.insert(0, 'label')\n",
    "\n",
    "labels_prob = [str(label) for label in probab]\n",
    "labels_prob.insert(0, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_array_pred = np.vstack((index, labels_pred)).T.astype('str')\n",
    "submission_array_prob = np.vstack((index, labels_prob)).T.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the array as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(path+'submissions/submission_pred.csv', submission_array_pred, delimiter=\",\", fmt='%1s')\n",
    "np.savetxt(path+'submissions/submission_prob.csv', submission_array_prob, delimiter=\",\", fmt='%1s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Submissions after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = len(os.listdir(path+'test'+'/subdir_for_keras_ImageDataGenerator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probab = np.load(path+'submissions/probab.npy')\n",
    "prediction = np.load(path+'submissions/prediction.npy')\n",
    "prediction_labels = np.load(path+'submissions/prediction_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.98002827,  1.        ,  1.        ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'cats', b'cats', b'cats', b'cats', b'dogs'],\n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for predicted, index in enumerate(prediction):\n",
    "    # When a cat is predicted, get the complimentary value\n",
    "    if predicted == 0:\n",
    "        probab[index] = 1 - probab[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.98002827,  1.        ,  1.        ,  1.        ,\n",
       "        0.99999928,  1.        ,  0.98711455,  1.        ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [str(i) for i in range(1, batch_size+1)]\n",
    "index.insert(0, 'id')\n",
    "\n",
    "labels_pred = [str(label) for label in prediction]\n",
    "labels_pred.insert(0, 'label')\n",
    "\n",
    "labels_prob = [str(label) for label in probab]\n",
    "labels_prob.insert(0, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_array_pred = np.vstack((index, labels_pred)).T.astype('str')\n",
    "submission_array_prob = np.vstack((index, labels_prob)).T.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(path+'submissions/submission_pred.csv', submission_array_pred, delimiter=\",\", fmt='%1s')\n",
    "np.savetxt(path+'submissions/submission_prob.csv', submission_array_prob, delimiter=\",\", fmt='%1s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
