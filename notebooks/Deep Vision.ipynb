{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Vision\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author** : Aman Hussain  \n",
    "**Email** : aman@amandavinci.me  \n",
    "**Description** : Classifying images of dogs and cats by finetuning the VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scientific Computing Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "from helper import utils\n",
    "from helper.utils import plots\n",
    "\n",
    "from helper import vgg16\n",
    "from helper.vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring paths & global parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the dataset is defined here. It will point to the sample folder which contains lesser number of images for quick and iterative training on the local machine. For the final training, on the cloud we must change the path to the one commented out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = '../data/dogscats/sample/'\n",
    "path = '../data/dogscats/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default batchsize for training and validation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the VGG16 class which implements the required utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.fast.ai/models/vgg16.h5\n",
      "553484288/553482496 [==============================] - 53s    \n",
      "Downloading data from http://files.fast.ai/models/imagenet_class_index.json\n",
      "32768/35363 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the training and validation batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', batch_size=batchsize)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the images, only if we are exploring the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if path == '../data/dogscats/sample/':\n",
    "    imgs, labels = next(batches)\n",
    "    val_imgs, val_labels = next(val_batches)\n",
    "    labels = ['dog' if i[0]==0 else 'cat' for i in labels]\n",
    "    val_labels = ['dog' if i[0]==0 else 'cat' for i in val_labels]\n",
    "    plots(val_imgs, figsize=(20,10), titles=val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 636s - loss: 0.1244 - acc: 0.9671 - val_loss: 0.0660 - val_acc: 0.9820\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 633s - loss: 0.0960 - acc: 0.9774 - val_loss: 0.0590 - val_acc: 0.9852\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 634s - loss: 0.0884 - acc: 0.9783 - val_loss: 0.0638 - val_acc: 0.9856\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 634s - loss: 0.0993 - acc: 0.9780 - val_loss: 0.0654 - val_acc: 0.9842\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 633s - loss: 0.0880 - acc: 0.9806 - val_loss: 0.0716 - val_acc: 0.9832\n",
      "CPU times: user 1h 3min 27s, sys: 12min 31s, total: 1h 15min 59s\n",
      "Wall time: 54min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vgg.fit(batches, val_batches, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the quirkiness of the ImageDataGenerator.flow_from_directory() used by vgg.get_batches(), we have to make a sub directory under test directory by the name 'subdir_for_keras_ImageDataGenerator'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = len(os.listdir(path+'test'+'/subdir_for_keras_ImageDataGenerator'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the class_mode set to None, it will return only the batch of images without labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "testbatch = vgg.get_batches(path+'test', shuffle=False, batch_size=batch_size, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs = next(testbatch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,we visualize the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if path == '../data/dogscats/sample/':\n",
    "    plots(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we make the predictions using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 10s, sys: 1min 15s, total: 5min 25s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "probab, prediction, prediction_labels = vgg.predict(test_imgs, details = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing to save the predictions as submissions to the Kaggle competetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(path+'submissions/probab', probab)\n",
    "np.save(path+'submissions/prediction', prediction)\n",
    "np.save(path+'submissions/prediction_labels', prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = [str(i) for i in range(1, batch_size+1)]\n",
    "index.insert(0, 'id')\n",
    "\n",
    "labels_pred = [str(label) for label in prediction]\n",
    "labels_pred.insert(0, 'label')\n",
    "\n",
    "labels_prob = [str(label) for label in probab]\n",
    "labels_prob.insert(0, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_array_pred = np.vstack((index, labels_pred)).T.astype('str')\n",
    "submission_array_prob = np.vstack((index, labels_prob)).T.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the array as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(path+'submissions/submission_pred.csv', submission_array_pred, delimiter=\",\", fmt='%1s')\n",
    "np.savetxt(path+'submissions/submission_prob.csv', submission_array_prob, delimiter=\",\", fmt='%1s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
