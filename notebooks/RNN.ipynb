{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9959, -0.0094, -0.8107],\n",
       "        [-1.9418, -1.5982, -0.5297],\n",
       "        [ 0.2225,  0.9908,  0.1086],\n",
       "        [ 0.5519,  0.6413,  0.2606],\n",
       "        [ 0.2096, -1.8712, -0.5589]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [torch.randn(1,3) for _ in range(5)]\n",
    "torch.cat(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9959, -0.0094, -0.8107]],\n",
       "\n",
       "        [[-1.9418, -1.5982, -0.5297]],\n",
       "\n",
       "        [[ 0.2225,  0.9908,  0.1086]],\n",
       "\n",
       "        [[ 0.5519,  0.6413,  0.2606]],\n",
       "\n",
       "        [[ 0.2096, -1.8712, -0.5589]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(x).view(5, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hid = lstm(torch.cat(x).view(5, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0213, -0.0101,  0.1333]],\n",
       "\n",
       "        [[ 0.1576, -0.3163,  0.0579]],\n",
       "\n",
       "        [[ 0.0163, -0.0553,  0.1200]],\n",
       "\n",
       "        [[ 0.0055,  0.0230,  0.1197]],\n",
       "\n",
       "        [[ 0.1879, -0.0805,  0.1540]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0213, -0.0101,  0.1333]]])\n",
      "tensor([[[ 0.1610, -0.2864, -0.0352]]])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[-2.9729,  4.6452,  8.1661]]])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[ 0.1586,  5.2490,  8.2591]]])\n",
      "tensor([[[ 0.1929, -0.0836,  0.0769]]])\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    out, hid = lstm(i.view(1,1,3))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "bs = 10\n",
    "lr = 0.001\n",
    "emb_sz = 42\n",
    "hid_sz = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(f'{PATH}/nietzsche.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to Truth, have been unskilled and unseemly methods for\n",
      "winning a woman? Certainly she has never allowed herself \n"
     ]
    }
   ],
   "source": [
    "print(text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60089"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text[:len(text)//10]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(text))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = {i:c for i,c in enumerate(vocab)}\n",
    "char2idx = {c:i for i,c in enumerate(vocab)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\x00', 1: 's', 2: 'b', 3: '!', 4: '5', 5: '0', 6: 'k', 7: '-', 8: 'z', 9: 'Y', 10: 'P', 11: 'e', 12: 'V', 13: '2', 14: 'c', 15: '7', 16: 'f', 17: '\"', 18: 'w', 19: 'L', 20: 'K', 21: 'm', 22: ']', 23: '(', 24: \"'\", 25: 'E', 26: 'i', 27: 'l', 28: ':', 29: '4', 30: 'H', 31: 'U', 32: 'C', 33: 'T', 34: 'q', 35: 'a', 36: 'B', 37: ',', 38: 'S', 39: 'A', 40: 'o', 41: '?', 42: 'W', 43: '8', 44: '_', 45: 'M', 46: 'h', 47: 'J', 48: '.', 49: '3', 50: '9', 51: 'X', 52: 'y', 53: 'j', 54: 'I', 55: 'v', 56: 'n', 57: 'd', 58: '1', 59: '\\n', 60: ')', 61: 'F', 62: 'R', 63: 'u', 64: 'O', 65: 't', 66: '6', 67: 'x', 68: 'D', 69: 'p', 70: 'g', 71: 'Q', 72: '[', 73: 'N', 74: ';', 75: ' ', 76: 'r', 77: 'G'}\n",
      "{'\\x00': 0, 's': 1, 'b': 2, '!': 3, '5': 4, '0': 5, 'k': 6, '-': 7, 'z': 8, 'Y': 9, 'P': 10, 'e': 11, 'V': 12, '2': 13, 'c': 14, '7': 15, 'f': 16, '\"': 17, 'w': 18, 'L': 19, 'K': 20, 'm': 21, ']': 22, '(': 23, \"'\": 24, 'E': 25, 'i': 26, 'l': 27, ':': 28, '4': 29, 'H': 30, 'U': 31, 'C': 32, 'T': 33, 'q': 34, 'a': 35, 'B': 36, ',': 37, 'S': 38, 'A': 39, 'o': 40, '?': 41, 'W': 42, '8': 43, '_': 44, 'M': 45, 'h': 46, 'J': 47, '.': 48, '3': 49, '9': 50, 'X': 51, 'y': 52, 'j': 53, 'I': 54, 'v': 55, 'n': 56, 'd': 57, '1': 58, '\\n': 59, ')': 60, 'F': 61, 'R': 62, 'u': 63, 'O': 64, 't': 65, '6': 66, 'x': 67, 'D': 68, 'p': 69, 'g': 70, 'Q': 71, '[': 72, 'N': 73, ';': 74, ' ': 75, 'r': 76, 'G': 77}\n"
     ]
    }
   ],
   "source": [
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexifying Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [char2idx[i] for i in text]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 62, 25, 61, 39, 32, 25, 59, 59, 59, 38, 31, 10, 10, 64, 38, 54, 73, 77, 75, 65, 46, 35, 65, 75, 33, 76, 63, 65, 46, 75, 26, 1, 75, 35, 75, 18, 40, 21, 35, 56, 7, 7, 18, 46, 35, 65, 75, 65, 46, 11, 56, 41, 75, 54, 1, 75, 65, 46, 11, 76, 11, 75, 56, 40, 65, 75, 70, 76, 40, 63, 56, 57, 59, 16, 40, 76, 75, 1, 63, 1, 69, 11, 14, 65, 26, 56, 70, 75, 65, 46, 35, 65, 75, 35, 27, 27, 75, 69, 46, 26, 27, 40, 1, 40, 69, 46, 11, 76, 1, 37, 75, 26, 56, 75, 1, 40, 75, 16, 35, 76, 75, 35, 1, 75, 65, 46, 11, 52, 75, 46, 35, 55, 11, 75, 2, 11, 11, 56, 59, 57, 40, 70, 21, 35, 65, 26, 1, 65, 1, 37, 75, 46, 35, 55, 11, 75, 16, 35, 26, 27, 11, 57, 75, 65, 40, 75, 63, 56, 57, 11, 76, 1, 65, 35, 56, 57, 75, 18, 40, 21, 11, 56, 7, 7, 65, 46, 35, 65, 75, 65, 46, 11, 75, 65, 11, 76, 76, 26, 2, 27, 11, 59, 1, 11, 76, 26, 40, 63, 1, 56, 11, 1, 1, 75, 35, 56, 57, 75, 14, 27, 63, 21, 1, 52, 75, 26, 21, 69, 40, 76, 65, 63, 56, 26, 65, 52, 75, 18, 26, 65, 46, 75, 18, 46, 26, 14, 46, 75, 65, 46, 11, 52, 75, 46, 35, 55, 11, 75, 63, 1, 63, 35, 27, 27, 52, 75, 69, 35, 26, 57, 59, 65, 46, 11, 26, 76, 75, 35, 57, 57, 76, 11, 1, 1, 11, 1, 75, 65, 40, 75, 33, 76, 63, 65, 46, 37, 75, 46, 35, 55, 11, 75, 2, 11, 11, 56, 75, 63, 56, 1, 6, 26, 27, 27, 11, 57, 75, 35, 56, 57, 75, 63, 56, 1, 11, 11, 21, 27, 52, 75, 21, 11, 65, 46, 40, 57, 1, 75, 16, 40, 76, 59, 18, 26, 56, 56, 26, 56, 70, 75, 35, 75, 18, 40, 21, 35, 56, 41, 75, 32, 11, 76, 65, 35, 26, 56, 27, 52, 75, 1, 46, 11, 75, 46, 35, 1, 75, 56, 11, 55, 11, 76, 75, 35, 27, 27, 40, 18, 11, 57, 75, 46, 11, 76, 1, 11, 27, 16, 75]\n",
      "PREFACE\n",
      "\n",
      "\n",
      "SUPPOSING that Truth is a woman--what then? Is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to Truth, have been unskilled and unseemly methods for\n",
      "winning a woman? Certainly she has never allowed herself \n"
     ]
    }
   ],
   "source": [
    "print(data[:400])\n",
    "print(''.join(idx2char[i] for i in data[:400]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Char3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=3\n",
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 3\n",
    "x1 = [data[i] for i in range(0, len(data)-seq, seq)]\n",
    "x2 = [data[i+1] for i in range(0, len(data)-seq, seq)]\n",
    "x3 = [data[i+2] for i in range(0, len(data)-seq, seq)]\n",
    "x4 = [data[i+3] for i in range(0, len(data)-seq, seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002, 2002, 2002, 2002)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x1), len(x2), len(x3), len(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(x1)\n",
    "x2 = np.stack(x2)\n",
    "x3 = np.stack(x3)\n",
    "x4 = np.stack(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 24, 82, 15, 69, 47, 82, 68, 68, 68]\n",
      "[59 15 82 68 59  1 64 75 25 51]\n",
      "[24 69 68  1 59  8 25 45 32 62]\n",
      "[82 47 68 35 80 52 62 62 22 75]\n",
      "[15 82 68 59  1 64 75 25 51 25]\n"
     ]
    }
   ],
   "source": [
    "print(data[:10])\n",
    "print(x1[:10])\n",
    "print(x2[:10])\n",
    "print(x3[:10])\n",
    "print(x4[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.stack([x1, x2, x3], axis=1), dtype=torch.long)\n",
    "y = torch.tensor(x4, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200297, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 59,  24,  82],\n",
       "        [ 15,  69,  47],\n",
       "        [ 82,  68,  68],\n",
       "        [ 68,   1,  35],\n",
       "        [ 59,  59,  80]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 15,  82,  68,  59,   1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set = torch.utils.data.TensorDataset(x, y)\n",
    "trn_ldr = torch.utils.data.DataLoader(dataset=trn_set, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(trn_ldr)\n",
    "x1, y1 = it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 3]), torch.Size([512]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 59,  24,  82]), tensor(15))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0], y1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_1, x1_2, x1_3 = x1[:,0], x1[:,1], x1[:,2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512]), torch.Size([512]), torch.Size([512]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_1.shape, x1_2.shape, x1_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(59), tensor(24), tensor(82))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_1[0], x1_2[0], x1_3[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[data[j+i] for i in range(seq)] for j in range(len(data)-seq)]\n",
    "x = np.stack(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60081, 8), array([10, 62, 25, 61, 39, 32, 25, 59]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [data[i+seq] for i in range(len(data)-seq)]\n",
    "y = np.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60081,), 59)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 62 25 61 39 32 25 59]\n",
      " [62 25 61 39 32 25 59 59]\n",
      " [25 61 39 32 25 59 59 59]\n",
      " [61 39 32 25 59 59 59 38]\n",
      " [39 32 25 59 59 59 38 31]]\n",
      "[59 59 38 31 10]\n"
     ]
    }
   ],
   "source": [
    "print(x[:5])\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60081, 8]), torch.Size([60081]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(x, dtype=torch.long)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 60081])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(1,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set = torch.utils.data.TensorDataset(x, y)\n",
    "trn_ldr = torch.utils.data.DataLoader(dataset=trn_set, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(trn_ldr)\n",
    "x1, y1 = it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.permute(1,0).shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 10,  62,  25,  61,  39,  32,  25,  59]), tensor(59))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0], y1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Char3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_sz, hid_sz, vocab_sz):\n",
    "        super(Char3, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz)\n",
    "        self.lin = nn.Linear(emb_sz, hid_sz)\n",
    "        self.hid = nn.Linear(hid_sz, hid_sz)\n",
    "        self.lout = nn.Linear(hid_sz, vocab_sz)\n",
    "    \n",
    "    def forward(self, x1, x2, x3):\n",
    "        in1 = F.relu(self.lin(self.emb(x1)))\n",
    "        in2 = F.relu(self.lin(self.emb(x2)))\n",
    "        in3 = F.relu(self.lin(self.emb(x3)))\n",
    "        \n",
    "        h = torch.zeros(in1.size(), dtype=torch.float).to(dev)\n",
    "        h = F.tanh(self.hid(h+in1))\n",
    "        h = F.tanh(self.hid(h+in2))\n",
    "        h = F.tanh(self.hid(h+in3))\n",
    "        \n",
    "        y = F.log_softmax(self.lout(h), dim=-1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_sz, hid_sz, vocab_sz):\n",
    "        super(RNN, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_sz, emb_sz)\n",
    "        self.lin = nn.Linear(emb_sz, hid_sz)\n",
    "        self.hid = nn.Linear(hid_sz, hid_sz)\n",
    "        self.lout = nn.Linear(hid_sz, vocab_sz)\n",
    "    \n",
    "    def forward(self, *xs):\n",
    "        bs = xs[0].size(0)\n",
    "        h = torch.zeros(bs, hid_sz, dtype=torch.float).to(dev)\n",
    "        for x in xs:\n",
    "            inp = F.relu(self.lin(self.emb(x)))        \n",
    "            h = F.tanh(self.hid(h+inp))\n",
    "        \n",
    "        y = F.log_softmax(self.lout(h), dim=-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Pytorch RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identity Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-output RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Char Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "char3md = Char3(emb_sz, hid_sz, len(vocab)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Char3(\n",
       "  (emb): Embedding(85, 42)\n",
       "  (lin): Linear(in_features=42, out_features=256, bias=True)\n",
       "  (hid): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lout): Linear(in_features=256, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char3md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = char3md(x1_1.to(dev), x1_2.to(dev), x1_3.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"; 1\\nPf!V_Spa[gpÆkHÆH5ä]gp\\nD]5!?q?7ÆK]7 E5! Hwi[tk2w G5æG-p\"]-!_qg?)=\\nTDnæH[q]vwp=pÆ_w\\n?n[I]EqNHpæf HwæexWp]G!y7Hq=[n);kq5\\n__n=pxw_))7R\"ppBY9pwn]u\\x00[2]H-TnptDMvj[\"XGm55pDfc75qDHDRH7E[]_pkT GWMfoUpw\"5HCi]nqWM55DXHT_!gppCnVK\\n5qDHC_K(z_c(MfoU5tnp3T_.M=p?j)!wDP\\nw]VldBHpTk[mE_wRn?D7Gæ=TDng[P]rU?5H[)D_pgnp?UÆG]QwæG-i)HTDD\\nætdz5HkHpDXÆ]Dn2æH3T_DQVÆD5HU55_w=Æ\"..éq!2G7?p!)5])[.\\nn[qD\\x005HKTy-t[g_65Hq\"T,ED(\"DqthWT7Hk;d\"_j_!wq!2G?nh)iWpÆtppÆDppM)np(és\\nwqcB])wnP=.nV!)[nVgElx7_EVKpÆ_\"!npÆ\";Sf5S7w7K)n?DY6Hq_\\np\"qVDG3PD)RKë!]5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred = np.argmax(y1_pred.detach().cpu().numpy(), 1)\n",
    "''.join(idx2char[i] for i in y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(md, trn_ldr, lr=0.001, epochs=1, name='rnn'):\n",
    "    md = md.to(dev)\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(md.parameters(), lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(trn_ldr,0):\n",
    "            #  preformat input\n",
    "            x1, x2, x3 = x[:,0].to(dev), x[:,1].to(dev), x[:,2].to(dev)\n",
    "            y = y.to(dev)\n",
    "            \n",
    "            # forward\n",
    "            out = md(x1,x2,x3)\n",
    "            loss = criterion(out, y)\n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print status\n",
    "            if (i%50) == 49:\n",
    "                print(\"Epoch:{} Iterations:{} Loss:{}\".format(epoch+1, i+1, loss.item()))\n",
    "    # Save\n",
    "    torch.save(md.state_dict(), \"../models/{}.ckpt\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Iterations:50 Loss:4.76631498336792\n",
      "Epoch:1 Iterations:100 Loss:4.85749626159668\n",
      "Epoch:1 Iterations:150 Loss:4.816066741943359\n",
      "Epoch:1 Iterations:200 Loss:4.974685192108154\n",
      "Epoch:1 Iterations:250 Loss:4.972196102142334\n",
      "Epoch:1 Iterations:300 Loss:4.90360164642334\n",
      "Epoch:1 Iterations:350 Loss:4.88721227645874\n",
      "Epoch:2 Iterations:50 Loss:4.740199089050293\n",
      "Epoch:2 Iterations:100 Loss:4.835621356964111\n",
      "Epoch:2 Iterations:150 Loss:4.78948450088501\n",
      "Epoch:2 Iterations:200 Loss:4.947761535644531\n",
      "Epoch:2 Iterations:250 Loss:4.953901290893555\n",
      "Epoch:2 Iterations:300 Loss:4.8849287033081055\n",
      "Epoch:2 Iterations:350 Loss:4.870678901672363\n",
      "Epoch:3 Iterations:50 Loss:4.716228008270264\n",
      "Epoch:3 Iterations:100 Loss:4.816891193389893\n",
      "Epoch:3 Iterations:150 Loss:4.7695231437683105\n",
      "Epoch:3 Iterations:200 Loss:4.924459934234619\n",
      "Epoch:3 Iterations:250 Loss:4.939205646514893\n",
      "Epoch:3 Iterations:300 Loss:4.870082378387451\n",
      "Epoch:3 Iterations:350 Loss:4.858486652374268\n",
      "Epoch:4 Iterations:50 Loss:4.6978960037231445\n",
      "Epoch:4 Iterations:100 Loss:4.800765514373779\n",
      "Epoch:4 Iterations:150 Loss:4.753288745880127\n",
      "Epoch:4 Iterations:200 Loss:4.9042181968688965\n",
      "Epoch:4 Iterations:250 Loss:4.927508354187012\n",
      "Epoch:4 Iterations:300 Loss:4.857773303985596\n",
      "Epoch:4 Iterations:350 Loss:4.848428249359131\n",
      "Epoch:5 Iterations:50 Loss:4.6852569580078125\n",
      "Epoch:5 Iterations:100 Loss:4.788425445556641\n",
      "Epoch:5 Iterations:150 Loss:4.740106582641602\n",
      "Epoch:5 Iterations:200 Loss:4.888169288635254\n",
      "Epoch:5 Iterations:250 Loss:4.9174885749816895\n",
      "Epoch:5 Iterations:300 Loss:4.847423553466797\n",
      "Epoch:5 Iterations:350 Loss:4.838016986846924\n"
     ]
    }
   ],
   "source": [
    "train(char3md, trn_ldr, 0.001, epochs, name='rnn0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(emb_sz, hid_sz, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (emb): Embedding(78, 42)\n",
       "  (lin): Linear(in_features=42, out_features=256, bias=True)\n",
       "  (hid): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lout): Linear(in_features=256, out_features=78, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = rnn(x1.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 85])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"FZ'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred = np.argmax(y1_pred.detach().cpu().numpy(), 1)\n",
    "''.join(idx2char[i] for i in y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = iter(trn_ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "(*x, y) = next(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(x[0]), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(md, trn_ldr, lr=0.001, epochs=1, name='rnn'):\n",
    "    md = md.to(dev)\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(md.parameters(), lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(trn_ldr,0):\n",
    "            #  preformat input\n",
    "            x = x.permute(1,0)\n",
    "            x, y = x.to(dev), y.to(dev)\n",
    "            \n",
    "            # forward\n",
    "            out = md(x1,x2,x3)\n",
    "            loss = criterion(out, y)\n",
    "            \n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print status\n",
    "            if (i%50) == 49:\n",
    "                print(\"Epoch:{} Iterations:{} Loss:{}\".format(epoch+1, i+1, loss.item()))\n",
    "    # Save\n",
    "    torch.save(md.state_dict(), \"../models/{}.ckpt\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Iterations:50 Loss:6.045565605163574\n",
      "Epoch:1 Iterations:100 Loss:5.852102279663086\n",
      "Epoch:1 Iterations:150 Loss:5.7982869148254395\n",
      "Epoch:1 Iterations:200 Loss:5.889673709869385\n",
      "Epoch:1 Iterations:250 Loss:5.715638160705566\n",
      "Epoch:1 Iterations:300 Loss:5.8514404296875\n",
      "Epoch:1 Iterations:350 Loss:5.752878665924072\n",
      "Epoch:1 Iterations:400 Loss:5.748596668243408\n",
      "Epoch:1 Iterations:450 Loss:5.922341346740723\n",
      "Epoch:1 Iterations:500 Loss:5.782570838928223\n",
      "Epoch:1 Iterations:550 Loss:5.582164764404297\n",
      "Epoch:1 Iterations:600 Loss:5.74899959564209\n",
      "Epoch:1 Iterations:650 Loss:5.5965576171875\n",
      "Epoch:1 Iterations:700 Loss:5.500996112823486\n",
      "Epoch:1 Iterations:750 Loss:5.859821796417236\n",
      "Epoch:1 Iterations:800 Loss:5.688898086547852\n",
      "Epoch:1 Iterations:850 Loss:5.668003082275391\n",
      "Epoch:1 Iterations:900 Loss:5.746268272399902\n",
      "Epoch:1 Iterations:950 Loss:5.67934513092041\n",
      "Epoch:1 Iterations:1000 Loss:5.557328224182129\n",
      "Epoch:1 Iterations:1050 Loss:5.622857570648193\n",
      "Epoch:1 Iterations:1100 Loss:5.734133720397949\n",
      "Epoch:1 Iterations:1150 Loss:5.616336345672607\n",
      "Epoch:2 Iterations:50 Loss:5.793947696685791\n",
      "Epoch:2 Iterations:100 Loss:5.504091262817383\n",
      "Epoch:2 Iterations:150 Loss:5.468509197235107\n",
      "Epoch:2 Iterations:200 Loss:5.6918416023254395\n",
      "Epoch:2 Iterations:250 Loss:5.485042572021484\n",
      "Epoch:2 Iterations:300 Loss:5.635862350463867\n",
      "Epoch:2 Iterations:350 Loss:5.60281229019165\n",
      "Epoch:2 Iterations:400 Loss:5.568398952484131\n",
      "Epoch:2 Iterations:450 Loss:5.816399574279785\n",
      "Epoch:2 Iterations:500 Loss:5.661342144012451\n",
      "Epoch:2 Iterations:550 Loss:5.464974403381348\n",
      "Epoch:2 Iterations:600 Loss:5.634097099304199\n",
      "Epoch:2 Iterations:650 Loss:5.459715366363525\n",
      "Epoch:2 Iterations:700 Loss:5.391780376434326\n",
      "Epoch:2 Iterations:750 Loss:5.706542491912842\n",
      "Epoch:2 Iterations:800 Loss:5.552264213562012\n",
      "Epoch:2 Iterations:850 Loss:5.518098831176758\n",
      "Epoch:2 Iterations:900 Loss:5.627376556396484\n",
      "Epoch:2 Iterations:950 Loss:5.604468822479248\n",
      "Epoch:2 Iterations:1000 Loss:5.45999813079834\n",
      "Epoch:2 Iterations:1050 Loss:5.573997497558594\n",
      "Epoch:2 Iterations:1100 Loss:5.632375717163086\n",
      "Epoch:2 Iterations:1150 Loss:5.553581714630127\n",
      "Epoch:3 Iterations:50 Loss:5.721705913543701\n",
      "Epoch:3 Iterations:100 Loss:5.430933952331543\n",
      "Epoch:3 Iterations:150 Loss:5.397670745849609\n",
      "Epoch:3 Iterations:200 Loss:5.629645824432373\n",
      "Epoch:3 Iterations:250 Loss:5.418834209442139\n",
      "Epoch:3 Iterations:300 Loss:5.567259788513184\n",
      "Epoch:3 Iterations:350 Loss:5.559317111968994\n",
      "Epoch:3 Iterations:400 Loss:5.507569789886475\n",
      "Epoch:3 Iterations:450 Loss:5.776787281036377\n",
      "Epoch:3 Iterations:500 Loss:5.581341743469238\n",
      "Epoch:3 Iterations:550 Loss:5.407752990722656\n",
      "Epoch:3 Iterations:600 Loss:5.587499618530273\n",
      "Epoch:3 Iterations:650 Loss:5.405156135559082\n",
      "Epoch:3 Iterations:700 Loss:5.360680103302002\n",
      "Epoch:3 Iterations:750 Loss:5.658910751342773\n",
      "Epoch:3 Iterations:800 Loss:5.499765396118164\n",
      "Epoch:3 Iterations:850 Loss:5.449006080627441\n",
      "Epoch:3 Iterations:900 Loss:5.564637184143066\n",
      "Epoch:3 Iterations:950 Loss:5.571678161621094\n",
      "Epoch:3 Iterations:1000 Loss:5.4207868576049805\n",
      "Epoch:3 Iterations:1050 Loss:5.542288303375244\n",
      "Epoch:3 Iterations:1100 Loss:5.602635383605957\n",
      "Epoch:3 Iterations:1150 Loss:5.528324604034424\n",
      "Epoch:4 Iterations:50 Loss:5.685438632965088\n",
      "Epoch:4 Iterations:100 Loss:5.408182621002197\n",
      "Epoch:4 Iterations:150 Loss:5.365761756896973\n",
      "Epoch:4 Iterations:200 Loss:5.614110946655273\n",
      "Epoch:4 Iterations:250 Loss:5.384241104125977\n",
      "Epoch:4 Iterations:300 Loss:5.540047645568848\n",
      "Epoch:4 Iterations:350 Loss:5.5380635261535645\n",
      "Epoch:4 Iterations:400 Loss:5.473390102386475\n",
      "Epoch:4 Iterations:450 Loss:5.754278182983398\n",
      "Epoch:4 Iterations:500 Loss:5.552091598510742\n",
      "Epoch:4 Iterations:550 Loss:5.375971794128418\n",
      "Epoch:4 Iterations:600 Loss:5.562710762023926\n",
      "Epoch:4 Iterations:650 Loss:5.383124828338623\n",
      "Epoch:4 Iterations:700 Loss:5.347771644592285\n",
      "Epoch:4 Iterations:750 Loss:5.6321611404418945\n",
      "Epoch:4 Iterations:800 Loss:5.476273536682129\n",
      "Epoch:4 Iterations:850 Loss:5.41677188873291\n",
      "Epoch:4 Iterations:900 Loss:5.5275983810424805\n",
      "Epoch:4 Iterations:950 Loss:5.555440425872803\n",
      "Epoch:4 Iterations:1000 Loss:5.39703369140625\n",
      "Epoch:4 Iterations:1050 Loss:5.513321876525879\n",
      "Epoch:4 Iterations:1100 Loss:5.593064785003662\n",
      "Epoch:4 Iterations:1150 Loss:5.506863117218018\n",
      "Epoch:5 Iterations:50 Loss:5.669096946716309\n",
      "Epoch:5 Iterations:100 Loss:5.388267517089844\n",
      "Epoch:5 Iterations:150 Loss:5.3363494873046875\n",
      "Epoch:5 Iterations:200 Loss:5.591930866241455\n",
      "Epoch:5 Iterations:250 Loss:5.359690189361572\n",
      "Epoch:5 Iterations:300 Loss:5.530918598175049\n",
      "Epoch:5 Iterations:350 Loss:5.515428066253662\n",
      "Epoch:5 Iterations:400 Loss:5.448476791381836\n",
      "Epoch:5 Iterations:450 Loss:5.740823745727539\n",
      "Epoch:5 Iterations:500 Loss:5.530904769897461\n",
      "Epoch:5 Iterations:550 Loss:5.355887413024902\n",
      "Epoch:5 Iterations:600 Loss:5.547189235687256\n",
      "Epoch:5 Iterations:650 Loss:5.368284702301025\n",
      "Epoch:5 Iterations:700 Loss:5.330353260040283\n",
      "Epoch:5 Iterations:750 Loss:5.596405506134033\n",
      "Epoch:5 Iterations:800 Loss:5.465329647064209\n",
      "Epoch:5 Iterations:850 Loss:5.391899108886719\n",
      "Epoch:5 Iterations:900 Loss:5.507032871246338\n",
      "Epoch:5 Iterations:950 Loss:5.544878005981445\n",
      "Epoch:5 Iterations:1000 Loss:5.388735771179199\n",
      "Epoch:5 Iterations:1050 Loss:5.502810478210449\n",
      "Epoch:5 Iterations:1100 Loss:5.579798221588135\n",
      "Epoch:5 Iterations:1150 Loss:5.488746643066406\n"
     ]
    }
   ],
   "source": [
    "train(char3md, trn_ldr, 0.001, epochs, name='rnn1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Iterations:50 Loss:5.958637237548828\n",
      "Epoch:1 Iterations:100 Loss:5.6186299324035645\n",
      "Epoch:1 Iterations:150 Loss:5.667288780212402\n",
      "Epoch:1 Iterations:200 Loss:5.905817031860352\n",
      "Epoch:1 Iterations:250 Loss:5.658107280731201\n",
      "Epoch:1 Iterations:300 Loss:5.804039001464844\n",
      "Epoch:1 Iterations:350 Loss:5.753924369812012\n",
      "Epoch:1 Iterations:400 Loss:5.762933731079102\n",
      "Epoch:1 Iterations:450 Loss:5.930180549621582\n",
      "Epoch:1 Iterations:500 Loss:5.850101947784424\n",
      "Epoch:1 Iterations:550 Loss:5.631256103515625\n",
      "Epoch:1 Iterations:600 Loss:5.76055383682251\n",
      "Epoch:1 Iterations:650 Loss:5.601725101470947\n",
      "Epoch:1 Iterations:700 Loss:5.539243221282959\n",
      "Epoch:1 Iterations:750 Loss:5.924337863922119\n",
      "Epoch:1 Iterations:800 Loss:5.716416358947754\n",
      "Epoch:1 Iterations:850 Loss:5.7156453132629395\n",
      "Epoch:1 Iterations:900 Loss:5.855612277984619\n",
      "Epoch:1 Iterations:950 Loss:5.806646823883057\n",
      "Epoch:1 Iterations:1000 Loss:5.676392555236816\n",
      "Epoch:1 Iterations:1050 Loss:5.733517169952393\n",
      "Epoch:1 Iterations:1100 Loss:5.838815212249756\n",
      "Epoch:1 Iterations:1150 Loss:5.770928859710693\n",
      "Epoch:2 Iterations:50 Loss:5.923406600952148\n",
      "Epoch:2 Iterations:100 Loss:5.665404319763184\n",
      "Epoch:2 Iterations:150 Loss:5.614418983459473\n",
      "Epoch:2 Iterations:200 Loss:5.836921215057373\n",
      "Epoch:2 Iterations:250 Loss:5.5869669914245605\n",
      "Epoch:2 Iterations:300 Loss:5.800543785095215\n",
      "Epoch:2 Iterations:350 Loss:5.779863357543945\n",
      "Epoch:2 Iterations:400 Loss:5.784833908081055\n",
      "Epoch:2 Iterations:450 Loss:5.9183759689331055\n",
      "Epoch:2 Iterations:500 Loss:5.805570125579834\n",
      "Epoch:2 Iterations:550 Loss:5.620512962341309\n",
      "Epoch:2 Iterations:600 Loss:5.754414081573486\n",
      "Epoch:2 Iterations:650 Loss:5.69248104095459\n",
      "Epoch:2 Iterations:700 Loss:5.547841548919678\n",
      "Epoch:2 Iterations:750 Loss:5.971591949462891\n",
      "Epoch:2 Iterations:800 Loss:5.735396862030029\n",
      "Epoch:2 Iterations:850 Loss:5.713109970092773\n",
      "Epoch:2 Iterations:900 Loss:5.848632335662842\n",
      "Epoch:2 Iterations:950 Loss:5.80363130569458\n",
      "Epoch:2 Iterations:1000 Loss:5.663960933685303\n",
      "Epoch:2 Iterations:1050 Loss:5.687324047088623\n",
      "Epoch:2 Iterations:1100 Loss:5.8286919593811035\n",
      "Epoch:2 Iterations:1150 Loss:5.757463455200195\n"
     ]
    }
   ],
   "source": [
    "train(char3md, trn_ldr, 0.01, 2, 'rnn2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CharModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inp):\n",
    "    x = torch.tensor(np.array([char2idx[c] for c in inp]))\n",
    "    p = char3md(x[0].to(dev), x[1].to(dev), x[2].to(dev))\n",
    "    print(p)\n",
    "    i = np.argmax(p.detach().cpu().numpy(),0)\n",
    "    return idx2char[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'='"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'='"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(' an')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(' is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(' yo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('The')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = rnn(x1.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.argmax(y1.detach().cpu().numpy(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor([ 31,  33,  75,   1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-eb9ecfc776fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-189-eb9ecfc776fd>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: tensor([ 31,  33,  75,   1])"
     ]
    }
   ],
   "source": [
    "''.join(idx2char[i] for i in x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"FZ'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx2char[i] for i in y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
